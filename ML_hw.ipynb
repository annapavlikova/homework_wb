{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40706e18-ad9c-4129-a6b5-1c37c4953132",
   "metadata": {},
   "source": [
    "### Домашнее задание: Регрессия\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18383c8-e48a-4df9-9e52-63b7495c4d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "**Цель**: Использовать набор данных по автомобилям для прогнозирования выбранной вами величины с использованием методов машинного обучения.\n",
    "\n",
    "**Данные**: Исходные данные можно найти на странице [UCI Machine Learning Repository: Automobile Dataset](https://archive.ics.uci.edu/ml/datasets/automobile). Этот набор данных содержит информацию о 205 автомобилях, включая их характеристики, такие как марка, тип кузова, колесная база, тип двигателя и многое другое.\n",
    "\n",
    "**Задача**: Выберите одну переменную из набора данных, которую вы хотели бы предсказать, и используйте для этого подходящие методы машинного обучения. Ваш выбор может основываться на интересе к конкретной характеристике автомобиля или на сложности прогнозируемой переменной.\n",
    "\n",
    "**Минимальные требования**:\n",
    "1. Обучите модель линейной регрессии на выбранных вами данных.\n",
    "2. Оцените качество модели, проанализируйте полученные результаты.\n",
    "\n",
    "**Рекомендации**:\n",
    "- Вы можете использовать любые библиотеки машинного обучения\n",
    "- Не ограничивайтесь только линейной регрессией. Если у вас есть опыт работы с другими типами моделей, такими как деревья решений, случайные леса, градиентный бустинг или нейронные сети, вы можете использовать их.\n",
    "- Визуализируйте данные для лучшего понимания и интерпретации результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be6bdc-548c-4af0-a423-3a14cc76a6f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Домашнее задание: Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1cbb7-b41c-4e4f-b873-bf65b7d8fd44",
   "metadata": {
    "tags": []
   },
   "source": [
    "Теоретическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3b78d-1075-4d67-a146-ad91862a9142",
   "metadata": {},
   "source": [
    "\n",
    "**Вопрос 1: Решение Задачи Бинарной Классификации с Несбалансированными Классами**\n",
    "\n",
    "Представьте ситуацию: к вам обратился заказчик с задачей бинарной классификации для прогнозирования оттока пользователей. В данных наблюдается существенный дисбаланс классов. Заказчик имеет ограниченные знания в области машинного обучения. Опишите, какие метрики классификации вы бы использовали для оценки модели классиификации в этом контексте и какие подходы можно применить для решения этой задачи кроме обычного предсказания 0/1?\n",
    "\n",
    "**Вопрос 2: Анализ Пользовательских Данных и Выявление Инсайтов**\n",
    "\n",
    "Бизнес-клиент предоставил вам обширный датасет о пользователях, содержащий множество различных признаков. Задача состоит в том, чтобы найти ценную информацию о пользователях, не ограничиваясь анализом отдельных фич. Какие методы и подходы машинного обучения вы бы предложили для извлечения полезных инсайтов из данных? Как вы можете использовать комбинацию признаков для получения более глубокого понимания пользовательского поведения?\n",
    "\n",
    "**Вопрос 3: Применение ROC-AUC в Контексте Реальных Задач**\n",
    "\n",
    "Объясните, что такое метрика ROC-AUC и почему она важна в контексте оценки производительности моделей классификации. Приведите пример реальной задачи, где использование ROC-AUC может быть особенно полезным, и опишите, как эта метрика может помочь в интерпретации результатов модели. Подумайте о сценарии, в котором точность предсказания имеет критическое значение, и как ROC-AUC может помочь в улучшении качества моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834323d-f952-4ded-982d-576dceb091cf",
   "metadata": {},
   "source": [
    "Практическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92683ebc-b409-462a-8f2b-69c08dd24c8b",
   "metadata": {},
   "source": [
    "1. Написать руками простое дерево решений\n",
    "2. Вывести логлосс из функции правдоподобия\n",
    "3. Написать руками логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006af72",
   "metadata": {},
   "source": [
    "**Вопрос 1**\n",
    "\n",
    "Опишите, какие метрики классификации вы бы использовали для оценки модели классиификации в этом контексте и какие подходы можно применить для решения этой задачи кроме обычного предсказания 0/1?\n",
    "\n",
    "Для оценки модели классификации можно использовать Precision и Recall, так как они не зависят от соотношения классов и потому применимы в условиях несбалансированных выборок. Так же можно применить AUC-ROC — площадь под кривой ошибок. Критерий AUC-ROC устойчив к несбалансированным классам и может быть интерпретирован как вероятность того, что случайно выбранный positive объект будет проранжирован классификатором выше (будет иметь более высокую вероятность быть positive), чем случайно выбранный negative объект.\n",
    "\n",
    "Для решения задачи бинарной классификации с дисбалансом классов, кроме обычного предсказания 0/1, можно применить следующие подходы:\n",
    "\n",
    "1.назначить различные веса классам в зависимости от их доли в данных\n",
    "\n",
    "2.undersampling- уменьшение количества объектов в преобладающем классе\n",
    "\n",
    "3.использовать алгоритмы случайного леса или градиентного бустинга, которые умеют учитывать дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361eda79",
   "metadata": {},
   "source": [
    "**Вопрос 2**\n",
    "\n",
    "Какие методы и подходы машинного обучения вы бы предложили для извлечения полезных инсайтов из данных? Как вы можете использовать комбинацию признаков для получения более глубокого понимания пользовательского поведения?\n",
    "\n",
    "Методы и подходы:\n",
    "\n",
    "1. Кластеризация - группировка пользователей по их сходству на основе каких-либо признаков (например, можно выделить кластеры пользователей с похожими покупательскими привычками).\n",
    "2. Классификация - предсказание категории или метки для каждого пользователя на основе их признаков.\n",
    "3. Регрессия - для предсказания числового значения, например, ожидаемой выручки от каждого пользователя или вероятности совершения определенного действия.\n",
    "4. Ассоциативные правила - для выявления скрытых взаимосвязей между различными признаками пользователей (например, можно определить, какие признаки чаще всего встречаются вместе).\n",
    "\n",
    "Для получения более глубокого понимания пользовательского поведения можно использовать комбинацию признаков и провести дополнительный анализ, например: факторный анализ для выявления основных факторов, влияющих на поведение пользователей, построение нейронных сетей для моделирования сложных зависимостей между признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd0561",
   "metadata": {},
   "source": [
    "**Вопрос 3**\n",
    "\n",
    "Объясните, что такое метрика ROC-AUC и почему она важна в контексте оценки производительности моделей классификации. \n",
    "Приведите пример реальной задачи, где использование ROC-AUC может быть особенно полезным, и опишите, как эта метрика \n",
    "может помочь в интерпретации результатов модели. Подумайте о сценарии, в котором точность предсказания имеет критическое значение, и как ROC-AUC может помочь в улучшении качества моделирования.\n",
    "\n",
    "Метрика ROC-AUC используется для измерения производительности моделей машинного обучения в задачах бинарной классификации. ROC-AUC представляет собой площадь под кривой ошибок.  Данная кривая представляет из себя линию от (0,0) до (1,1) в координатах True Positive Rate (TPR) и False Positive Rate (FPR):\n",
    "\n",
    "\n",
    "$\\large TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "\n",
    "$\\large FPR = \\frac{FP}{FP + TN}$\n",
    "\n",
    "В идеальном случае, когда классификатор не делает ошибок (FPR = 0, TPR = 1) мы получим площадь под кривой, равную единице; в противном случае, когда классификатор случайно выдает вероятности классов, AUC-ROC будет стремиться к 0.5, так как классификатор будет выдавать одинаковое количество TP и FP.\n",
    "\n",
    "ROC-AUC важна в контексте оценки производительности моделей классификации, так как она позволяет сравнивать модели с разными порогами классификации и выбирать наилучший вариант в зависимости от конкретной задачи. Более высокое значение ROC-AUC указывает на лучшую производительность модели, что может быть особенно полезным в задачах, где важна как чувствительность (вероятность правильного определения положительного класса), так и специфичность (вероятность правильного определения отрицательного класса).\n",
    "\n",
    "Пример реальной задачи - задача определения риска заболевания у пациентов на основе медицинских данных. В данном случае, точность предсказания имеет критическое значение, так как неверное прогнозирование может привести к неправильному лечению или пропуску необходимого лечения.\n",
    "\n",
    "ROC-AUC может помочь в улучшении качества моделирования в таких сценариях, позволяя анализировать и сравнивать различные модели с разными порогами классификации и выбирать наилучший вариант с учетом баланса между чувствительностью и специфичностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c44a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Практическая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d196e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb12abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96995be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_idx=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_idx = feature_idx    # индекс признака, по которому разбивается вершина\n",
    "        self.threshold = threshold        # пороговое значение, по которому разбивается вершина\n",
    "        self.left = left                  # левое поддерево\n",
    "        self.right = right                # правое поддерево\n",
    "        self.value = value                # значение в листовой вершине\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split   # минимальное количество выборок, необходимых для разделения вершины\n",
    "        self.max_depth = max_depth                   # максимальная глубина дерева\n",
    "        self.n_feats = n_feats                       # количество признаков, используемых для разделения вершин\n",
    "        self.root = None\n",
    "    def fit(self, X, y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        # Проверяем условие остановки рекурсии\n",
    "        if (depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "        # Ищем лучшее разделение признака\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "        # Разделяем данные и делаем рекурсивный вызов для левого и правого поддеревьев\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "        # Возвращаем новую вершину дерева\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "        return split_idx, split_thresh\n",
    "    def _information_gain(self, y, X_column, split_thresh):\n",
    "        # Вычисляем энтропию перед разбиением\n",
    "        parent_entropy = self._entropy(y)\n",
    "        # Разделяем выборки по пороговому значению\n",
    "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
    "        # Если разделение не привело к изменению выборок, возвращаем нулевой информационный прирост\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        # Вычисляем энтропию после разбиения\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "        # Вычисляем информационный прирост\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "    def _entropy(self, y):\n",
    "        # Вычисляем энтропию выборки\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probs = counts / len(y)\n",
    "        entropy = -np.sum(probs * np.log2(probs))\n",
    "        return entropy\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        # Разделяем выборки по пороговому значению\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "    def _most_common_label(self, y):\n",
    "        # Возвращает наиболее часто встречающееся значение в выборке\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        return max(zip(_, counts), key=lambda x: x[1])[0]\n",
    "    def predict(self, X):\n",
    "        # Прогнозируем метки для новых данных\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature_idx] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "    def visualize_tree(self):\n",
    "        # Создаем объект `Digraph` из библиотеки graphviz\n",
    "        dot = graphviz.Digraph()\n",
    "        # Внутренняя функция `add_nodes` для рекурсивного добавления узлов дерева\n",
    "        def add_nodes(node):\n",
    "            # Если узел содержит значение (лист), добавляем его значение в качестве метки\n",
    "            # Иначе добавляем условие разбиения (порог и номер признака)\n",
    "            if node.value is not None:\n",
    "                label = str(node.value)\n",
    "            else:\n",
    "                label = \"X[\" + str(node.feature_idx) + \"] <= \" + str(node.threshold)\n",
    "            # Добавляем узел в объект `Digraph`\n",
    "            dot.node(str(id(node)), label)\n",
    "            # Если у узла есть левый потомок, добавляем ребро и вызываем `add_nodes` для левого потомка\n",
    "            if node.left is not None:\n",
    "                dot.edge(str(id(node)), str(id(node.left)))\n",
    "                add_nodes(node.left)\n",
    "            # Если у узла есть правый потомок, добавляем ребро и вызываем `add_nodes` для правого потомка\n",
    "            if node.right is not None:\n",
    "                dot.edge(str(id(node)), str(id(node.right)))\n",
    "                add_nodes(node.right)\n",
    "        # Вызываем `add_nodes` для корневого узла дерева\n",
    "        add_nodes(self.root)\n",
    "        # Возвращаем объект `Digraph`\n",
    "        return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e966b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "automobile = fetch_ucirepo(id=10)\n",
    "\n",
    "X = automobile.data.features \n",
    "y = automobile.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a826053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = automobile.data.features \n",
    "y = automobile.data.targets \n",
    "\n",
    "X=X.to_numpy()\n",
    "X = X[:,[0, 1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,20]]\n",
    "y=y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b8d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_10640/2188158053.py:70: RuntimeWarning: invalid value encountered in less_equal\n",
      "  left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
      "C:\\Users\\Anna\\AppData\\Local\\Temp/ipykernel_10640/2188158053.py:71: RuntimeWarning: invalid value encountered in greater\n",
      "  right_idxs = np.argwhere(X_column > split_thresh).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00         3\n",
      "          -1       0.71      0.45      0.56        22\n",
      "           0       0.66      0.69      0.67        67\n",
      "           1       0.65      0.76      0.70        54\n",
      "           2       0.41      0.47      0.43        32\n",
      "           3       0.90      0.70      0.79        27\n",
      "\n",
      "    accuracy                           0.64       205\n",
      "   macro avg       0.56      0.51      0.53       205\n",
      "weighted avg       0.65      0.64      0.64       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTree(max_depth=3)\n",
    "clf.fit(X, y)\n",
    "# Прогнозируем метки классов на тестовой выборке\n",
    "y_pred = clf.predict(X)\n",
    "print(classification_report(y, y_pred))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c115f4a",
   "metadata": {},
   "source": [
    "fmp = theta^n * (1-theta)^m\n",
    "logloss = n*log(theta) + m*log(1-theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e33d832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d087f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
